{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data and having a first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Park Code               Park Name State   Acres  Latitude  Longitude\n",
      "0      ACAD    Acadia National Park    ME   47390     44.35     -68.21\n",
      "1      ARCH    Arches National Park    UT   76519     38.68    -109.57\n",
      "2      BADL  Badlands National Park    SD  242756     43.75    -102.50\n",
      "3      BIBE  Big Bend National Park    TX  801163     29.25    -103.25\n",
      "4      BISC  Biscayne National Park    FL  172924     25.65     -80.08\n"
     ]
    }
   ],
   "source": [
    "#Importing species data and having a firt look\n",
    "parks = pd.read_csv('parks.csv')\n",
    "print(parks.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Species ID             Park Name Category         Order    Family  \\\n",
      "0  ACAD-1000  Acadia National Park   Mammal  Artiodactyla  Cervidae   \n",
      "1  ACAD-1001  Acadia National Park   Mammal  Artiodactyla  Cervidae   \n",
      "2  ACAD-1002  Acadia National Park   Mammal     Carnivora   Canidae   \n",
      "3  ACAD-1003  Acadia National Park   Mammal     Carnivora   Canidae   \n",
      "4  ACAD-1004  Acadia National Park   Mammal     Carnivora   Canidae   \n",
      "\n",
      "          Scientific Name                                       Common Names  \\\n",
      "0             Alces alces                                              Moose   \n",
      "1  Odocoileus virginianus  Northern White-Tailed Deer, Virginia Deer, Whi...   \n",
      "2           Canis latrans                             Coyote, Eastern Coyote   \n",
      "3             Canis lupus        Eastern Timber Wolf, Gray Wolf, Timber Wolf   \n",
      "4           Vulpes vulpes  Black Fox, Cross Fox, Eastern Red Fox, Fox, Re...   \n",
      "\n",
      "  Record Status     Occurrence  Nativeness Abundance Seasonality  \\\n",
      "0      Approved        Present      Native      Rare    Resident   \n",
      "1      Approved        Present      Native  Abundant         NaN   \n",
      "2      Approved        Present  Not Native    Common         NaN   \n",
      "3      Approved  Not Confirmed      Native       NaN         NaN   \n",
      "4      Approved        Present     Unknown    Common     Breeder   \n",
      "\n",
      "  Conservation Status Unnamed: 13  \n",
      "0                 NaN         NaN  \n",
      "1                 NaN         NaN  \n",
      "2  Species of Concern         NaN  \n",
      "3          Endangered         NaN  \n",
      "4                 NaN         NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimka\\AppData\\Local\\Temp\\ipykernel_18240\\2715029833.py:2: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  species = pd.read_csv('species.csv')\n"
     ]
    }
   ],
   "source": [
    "#Importing parks data and having a firt look\n",
    "species = pd.read_csv('species.csv')\n",
    "print(species.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating on the Quality of teeh data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Park Code  56 non-null     object \n",
      " 1   Park Name  56 non-null     object \n",
      " 2   State      56 non-null     object \n",
      " 3   Acres      56 non-null     int64  \n",
      " 4   Latitude   56 non-null     float64\n",
      " 5   Longitude  56 non-null     float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 2.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Checking the quality of the data any missing values for the park dataset\n",
    "print(parks.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Park Code    0\n",
      "Park Name    0\n",
      "State        0\n",
      "Acres        0\n",
      "Latitude     0\n",
      "Longitude    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Looking for missing values\n",
    "print(parks.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Checking for duplicates\n",
    "print(parks.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119248 entries, 0 to 119247\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   Species ID           119248 non-null  object\n",
      " 1   Park Name            119248 non-null  object\n",
      " 2   Category             119248 non-null  object\n",
      " 3   Order                117776 non-null  object\n",
      " 4   Family               117736 non-null  object\n",
      " 5   Scientific Name      119248 non-null  object\n",
      " 6   Common Names         119248 non-null  object\n",
      " 7   Record Status        119248 non-null  object\n",
      " 8   Occurrence           99106 non-null   object\n",
      " 9   Nativeness           94203 non-null   object\n",
      " 10  Abundance            76306 non-null   object\n",
      " 11  Seasonality          20157 non-null   object\n",
      " 12  Conservation Status  4718 non-null    object\n",
      " 13  Unnamed: 13          5 non-null       object\n",
      "dtypes: object(14)\n",
      "memory usage: 12.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Checking the number of values and if there are any missing values for the species dataset\n",
    "print(species.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species ID                  0\n",
      "Park Name                   0\n",
      "Category                    0\n",
      "Order                    1472\n",
      "Family                   1512\n",
      "Scientific Name             0\n",
      "Common Names                0\n",
      "Record Status               0\n",
      "Occurrence              20142\n",
      "Nativeness              25045\n",
      "Abundance               42942\n",
      "Seasonality             99091\n",
      "Conservation Status    114530\n",
      "Unnamed: 13            119243\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Looking for missing values\n",
    "print(species.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Checking for duplicates\n",
    "print(species.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119248\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "#Chechikng the lenght of both datasets\n",
    "print(species.__len__())\n",
    "print(parks.__len__())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealling with the Missing Values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the investigation of both datasets, it was observed that the species dataset contained a high number of missing values, while the park dataset was considered to be complete. The species dataset had missing values primarily in the following categories: \n",
    "- Order\n",
    "- Family\n",
    "- Occurrence\n",
    "- Nativeness\n",
    "- Abundance\n",
    "- Seasonability\n",
    "- Conservation Status\n",
    "\n",
    "In any data analysis, missing or duplicated values must be appropriately addressed to prevent misleading results. Given the scientific nature of the data, any incorrect modifications of the data have the potential to corrupt the final results. Furthermore, drastic or misplaced data manipulation could similarly result in inaccuracies in further analyses. Therefore, identifying an appropriate method for data replacement is essential to ensure the accuracy and integrity of the final analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the significant amount of missing data in several columns, particularly in the \"Conservation Status\" column, deleting rows is not a viable option as it would result in the loss of valuable information. Therefore, alternative methods such as creating a Machine Learning model or performing imputation are necessary. However, due to the high proportion of missing values, these options could lead to data bias, which should be taken into account when selecting an approach.\n",
    "\n",
    "To facilitate some parts of the analysis, multiple \"species\" dataframes will be created, each with different methods of handling missing values: \n",
    "- species_df1: This dataframe will maintain all of the nan values.\n",
    "- species_df2: This dataframe will exclude the columns \"Conservation Status\" and \"Seasonality,\" and imputation using the median will be used to replace the remaining nan values.\n",
    "- species_df3: This dataframe will exclude the columns \"Conservation Status\" and \"Seasonality,\" and imputation using the mean will be used to replace the remaining nan values.\n",
    "\n",
    "Comparing the results obtained from each of these dataframes can provide a broader understanding of the data and ensure the accuracy of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119248\n"
     ]
    }
   ],
   "source": [
    "#dataset one with the initianel non cleaned dataset\n",
    "species_df1 = species\n",
    "print(species.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119248\n"
     ]
    }
   ],
   "source": [
    "#Creating the second dataset\n",
    "species_del_col = species.drop(columns=[\"Seasonality\", \"Conservation Status\"])\n",
    "\n",
    "print(species_del_col.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimka\\AppData\\Local\\Temp\\ipykernel_18240\\732385995.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  species_df2 = species.fillna(species.median())\n"
     ]
    }
   ],
   "source": [
    "#Creating the third dataset\n",
    "species_df2 = species.fillna(species.median())\n",
    "\n",
    "#print(species_df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species ID                  0\n",
      "Park Name                   0\n",
      "Category                    0\n",
      "Order                    1472\n",
      "Family                   1512\n",
      "Scientific Name             0\n",
      "Common Names                0\n",
      "Record Status               0\n",
      "Occurrence              20142\n",
      "Nativeness              25045\n",
      "Abundance               42942\n",
      "Seasonality             99091\n",
      "Conservation Status    114530\n",
      "Unnamed: 13            119243\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(species_df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the third dataset\n",
    "species_df3 = species.fillna(species.mean())\n",
    "\n",
    "#print(species_df3.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with the many missng values present in the Species dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is essential to consider that the final results of this analysis may be biased due to the drastic measures taken during the handling of missing values. Despite conducting the analysis with care and effort, the results obtained may not entirely represent the reality of the situation.\n",
    "\n",
    "To obtain more accurate results, it would have been preferable to use a Machine Learning model to replace the missing values in one of the dataframes. This would then allow multiple dataframes to be analyzed and compared to ascertain the validity of the results. This approach would minimize the impact of data loss while ensuring that the analysis is as accurate as possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e5b9983016a64168ff1fe3ecd76457b1b3f72b869902bf776cbc05e201d7728"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
